{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1ulOsOinJxEe"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ycNgwHElKCBX",
    "outputId": "81ab95b0-005e-4379-dfb2-9a27a7c54f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\raul\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\raul\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\raul\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\raul\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\raul\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\raul\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fTt47m7XKGHH"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8xJCifPJ-WQ",
    "outputId": "30d06ced-bf18-4368-d95f-213416460230"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59PT7n7LKLXn",
    "outputId": "85e3434f-e927-4371-afe0-1b46c662ecf3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvL5fhNOLcWH",
    "outputId": "a00a296b-8a38-4707-83e7-b6f06bb2446d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyserini\n",
      "  Downloading pyserini-0.23.0-py3-none-any.whl (140.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.5/140.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.10/dist-packages (from pyserini) (3.0.6)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from pyserini) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pyserini) (1.5.3)\n",
      "Collecting pyjnius>=1.4.0 (from pyserini)\n",
      "  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.10/dist-packages (from pyserini) (1.2.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyserini) (1.11.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pyserini) (4.66.1)\n",
      "Requirement already satisfied: transformers>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from pyserini) (4.35.2)\n",
      "Collecting sentencepiece>=0.1.95 (from pyserini)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nmslib>=2.1.1 (from pyserini)\n",
      "  Downloading nmslib-2.1.1.tar.gz (188 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting onnxruntime>=1.8.1 (from pyserini)\n",
      "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lightgbm>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from pyserini) (4.1.0)\n",
      "Requirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from pyserini) (3.6.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from pyserini) (6.0.1)\n",
      "Collecting openai>=1.0.0 (from pyserini)\n",
      "  Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tiktoken>=0.4.0 (from pyserini)\n",
      "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pybind11<2.6.2 (from nmslib>=2.1.1->pyserini)\n",
      "  Using cached pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from nmslib>=2.1.1->pyserini) (5.9.5)\n",
      "Collecting coloredlogs (from onnxruntime>=1.8.1->pyserini)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.8.1->pyserini) (23.5.26)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.8.1->pyserini) (23.2)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.8.1->pyserini) (3.20.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.8.1->pyserini) (1.12)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0.0->pyserini) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.0.0->pyserini) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai>=1.0.0->pyserini)\n",
      "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0.0->pyserini) (1.10.13)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.0.0->pyserini) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0.0->pyserini) (4.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->pyserini) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->pyserini) (2023.3.post1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.2.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (8.1.12)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (2.0.10)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (0.9.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (0.10.3)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (6.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (2.31.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (67.7.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.2.1->pyserini) (3.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.4.0->pyserini) (2023.6.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.6.0->pyserini) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.6.0->pyserini) (0.19.4)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.6.0->pyserini) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.6.0->pyserini) (0.4.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai>=1.0.0->pyserini) (3.6)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai>=1.0.0->pyserini) (1.2.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->pyserini) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.0.0->pyserini)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->pyserini)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.6.0->pyserini) (2023.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.4.0->pyserini) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.1->pyserini) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=3.2.1->pyserini) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy>=3.2.1->pyserini) (8.1.7)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.8.1->pyserini)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=3.2.1->pyserini) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.8.1->pyserini) (1.3.0)\n",
      "Building wheels for collected packages: nmslib\n",
      "  Building wheel for nmslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nmslib: filename=nmslib-2.1.1-cp310-cp310-linux_x86_64.whl size=13578647 sha256=b6d8e2f983d251ff56cb50cd3248da609e5c5a59fb2d07e0be3c7994a3605df4\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/1a/5d/4cc754a5b1a88405cad184b76f823897a63a8d19afcd4b9314\n",
      "Successfully built nmslib\n",
      "Installing collected packages: sentencepiece, pyjnius, pybind11, humanfriendly, h11, tiktoken, nmslib, httpcore, coloredlogs, onnxruntime, httpx, openai, pyserini\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed coloredlogs-15.0.1 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 humanfriendly-10.0 nmslib-2.1.1 onnxruntime-1.16.3 openai-1.3.7 pybind11-2.6.1 pyjnius-1.6.1 pyserini-0.23.0 sentencepiece-0.1.99 tiktoken-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyserini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmixblYeMr_-",
    "outputId": "2c739ea8-a36d-4da9-c270-2e1973cc84bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install torch faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vikb6gSnf2FY",
    "outputId": "536cc65c-0723-4e1a-9fa4-af2b05eaba9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement Lucene (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for Lucene\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "8u86jzmsLbmg"
   },
   "outputs": [],
   "source": [
    "from pyserini.search import SimpleSearcher\n",
    "from pyserini import analysis\n",
    "from pyserini.search import LuceneSearcher\n",
    "from pyserini.index import IndexReader\n",
    "from pyserini.analysis import Analyzer, get_lucene_analyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdKsG-ESkUyi",
    "outputId": "934590fc-c532-433a-b54a-4c9ffe857d69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.1.2\n",
      "    Uninstalling pip-23.1.2:\n",
      "      Successfully uninstalled pip-23.1.2\n",
      "Successfully installed pip-23.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Cq7llY7kW8J",
    "outputId": "d9cf424a-807e-4122-a8ce-d11cc756b9a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "libjpeg-dev is already the newest version (8c-2ubuntu10).\n",
      "libjpeg-dev set to manually installed.\n",
      "libxml2-dev is already the newest version (2.9.13+dfsg-1ubuntu0.3).\n",
      "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
      "The following additional packages will be installed:\n",
      "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript libgs9 libgs9-common libid3tag0\n",
      "  libidn12 libijs-0.35 libjbig2dec0 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
      "  libsox-fmt-base libsox3 libwavpack1 poppler-data python-is-python3 swig4.0 tesseract-ocr-eng\n",
      "  tesseract-ocr-osd\n",
      "Suggested packages:\n",
      "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf fonts-texgyre ghostscript-x lame-doc\n",
      "  libsox-fmt-all fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
      "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum swig-doc swig-examples\n",
      "  swig4.0-examples swig4.0-doc\n",
      "The following NEW packages will be installed:\n",
      "  antiword flac fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript lame libgs9\n",
      "  libgs9-common libid3tag0 libidn12 libijs-0.35 libjbig2dec0 libmad0 libopencore-amrnb0\n",
      "  libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base libsox-fmt-mp3 libsox3 libwavpack1\n",
      "  libxslt1-dev poppler-data poppler-utils pstotext python-dev-is-python3 python-is-python3 sox swig\n",
      "  swig4.0 tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd unrtf\n",
      "0 upgraded, 34 newly installed, 0 to remove and 15 not upgraded.\n",
      "Need to get 24.2 MB of archives.\n",
      "After this operation, 90.5 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 antiword amd64 0.37-16 [118 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 flac amd64 1.3.3-2ubuntu0.2 [130 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.5 [752 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.5 [5,030 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ghostscript amd64 9.55.0~dfsg1-0ubuntu5.5 [49.5 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lame amd64 3.100-3build2 [51.3 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libid3tag0 amd64 0.15.1b-14 [31.3 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmad0 amd64 0.15.1b-10ubuntu1 [63.1 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [240 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [11.2 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [33.7 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-mp3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [17.3 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libxslt1-dev amd64 1.1.34-4ubuntu0.22.04.1 [219 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.3 [186 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pstotext amd64 1.9-6build1 [32.4 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 python-is-python3 all 3.9.2-2 [2,788 B]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 python-dev-is-python3 all 3.9.2-2 [1,234 B]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 sox amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [104 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 unrtf amd64 0.21.10-clean-1 [45.0 kB]\n",
      "Fetched 24.2 MB in 9s (2,647 kB/s)\n",
      "Extracting templates from packages: 100%\n",
      "Selecting previously unselected package fonts-droid-fallback.\n",
      "(Reading database ... 120882 files and directories currently installed.)\n",
      "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
      "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
      "Selecting previously unselected package poppler-data.\n",
      "Preparing to unpack .../01-poppler-data_0.4.11-1_all.deb ...\n",
      "Unpacking poppler-data (0.4.11-1) ...\n",
      "Selecting previously unselected package antiword.\n",
      "Preparing to unpack .../02-antiword_0.37-16_amd64.deb ...\n",
      "Unpacking antiword (0.37-16) ...\n",
      "Selecting previously unselected package flac.\n",
      "Preparing to unpack .../03-flac_1.3.3-2ubuntu0.2_amd64.deb ...\n",
      "Unpacking flac (1.3.3-2ubuntu0.2) ...\n",
      "Selecting previously unselected package fonts-noto-mono.\n",
      "Preparing to unpack .../04-fonts-noto-mono_20201225-1build1_all.deb ...\n",
      "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
      "Selecting previously unselected package fonts-urw-base35.\n",
      "Preparing to unpack .../05-fonts-urw-base35_20200910-1_all.deb ...\n",
      "Unpacking fonts-urw-base35 (20200910-1) ...\n",
      "Selecting previously unselected package libgs9-common.\n",
      "Preparing to unpack .../06-libgs9-common_9.55.0~dfsg1-0ubuntu5.5_all.deb ...\n",
      "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.5) ...\n",
      "Selecting previously unselected package libidn12:amd64.\n",
      "Preparing to unpack .../07-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
      "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
      "Selecting previously unselected package libijs-0.35:amd64.\n",
      "Preparing to unpack .../08-libijs-0.35_0.35-15build2_amd64.deb ...\n",
      "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
      "Selecting previously unselected package libjbig2dec0:amd64.\n",
      "Preparing to unpack .../09-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
      "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
      "Selecting previously unselected package libgs9:amd64.\n",
      "Preparing to unpack .../10-libgs9_9.55.0~dfsg1-0ubuntu5.5_amd64.deb ...\n",
      "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.5) ...\n",
      "Selecting previously unselected package ghostscript.\n",
      "Preparing to unpack .../11-ghostscript_9.55.0~dfsg1-0ubuntu5.5_amd64.deb ...\n",
      "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.5) ...\n",
      "Selecting previously unselected package lame.\n",
      "Preparing to unpack .../12-lame_3.100-3build2_amd64.deb ...\n",
      "Unpacking lame (3.100-3build2) ...\n",
      "Selecting previously unselected package libid3tag0:amd64.\n",
      "Preparing to unpack .../13-libid3tag0_0.15.1b-14_amd64.deb ...\n",
      "Unpacking libid3tag0:amd64 (0.15.1b-14) ...\n",
      "Selecting previously unselected package libmad0:amd64.\n",
      "Preparing to unpack .../14-libmad0_0.15.1b-10ubuntu1_amd64.deb ...\n",
      "Unpacking libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
      "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
      "Preparing to unpack .../15-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
      "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
      "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
      "Preparing to unpack .../16-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
      "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
      "Selecting previously unselected package libsox3:amd64.\n",
      "Preparing to unpack .../17-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
      "Preparing to unpack .../18-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libwavpack1:amd64.\n",
      "Preparing to unpack .../19-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
      "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
      "Selecting previously unselected package libsox-fmt-base:amd64.\n",
      "Preparing to unpack .../20-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libsox-fmt-mp3:amd64.\n",
      "Preparing to unpack .../21-libsox-fmt-mp3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libxslt1-dev:amd64.\n",
      "Preparing to unpack .../22-libxslt1-dev_1.1.34-4ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libxslt1-dev:amd64 (1.1.34-4ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package poppler-utils.\n",
      "Preparing to unpack .../23-poppler-utils_22.02.0-2ubuntu0.3_amd64.deb ...\n",
      "Unpacking poppler-utils (22.02.0-2ubuntu0.3) ...\n",
      "Selecting previously unselected package pstotext.\n",
      "Preparing to unpack .../24-pstotext_1.9-6build1_amd64.deb ...\n",
      "Unpacking pstotext (1.9-6build1) ...\n",
      "Selecting previously unselected package python-is-python3.\n",
      "Preparing to unpack .../25-python-is-python3_3.9.2-2_all.deb ...\n",
      "Unpacking python-is-python3 (3.9.2-2) ...\n",
      "Selecting previously unselected package python-dev-is-python3.\n",
      "Preparing to unpack .../26-python-dev-is-python3_3.9.2-2_all.deb ...\n",
      "Unpacking python-dev-is-python3 (3.9.2-2) ...\n",
      "Selecting previously unselected package sox.\n",
      "Preparing to unpack .../27-sox_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package swig4.0.\n",
      "Preparing to unpack .../28-swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
      "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
      "Selecting previously unselected package swig.\n",
      "Preparing to unpack .../29-swig_4.0.2-1ubuntu1_all.deb ...\n",
      "Unpacking swig (4.0.2-1ubuntu1) ...\n",
      "Selecting previously unselected package tesseract-ocr-eng.\n",
      "Preparing to unpack .../30-tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
      "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
      "Selecting previously unselected package tesseract-ocr-osd.\n",
      "Preparing to unpack .../31-tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
      "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
      "Selecting previously unselected package tesseract-ocr.\n",
      "Preparing to unpack .../32-tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
      "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
      "Selecting previously unselected package unrtf.\n",
      "Preparing to unpack .../33-unrtf_0.21.10-clean-1_amd64.deb ...\n",
      "Unpacking unrtf (0.21.10-clean-1) ...\n",
      "Setting up unrtf (0.21.10-clean-1) ...\n",
      "Setting up libxslt1-dev:amd64 (1.1.34-4ubuntu0.22.04.1) ...\n",
      "Setting up fonts-noto-mono (20201225-1build1) ...\n",
      "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
      "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
      "Setting up fonts-urw-base35 (20200910-1) ...\n",
      "Setting up lame (3.100-3build2) ...\n",
      "Setting up poppler-data (0.4.11-1) ...\n",
      "Setting up libid3tag0:amd64 (0.15.1b-14) ...\n",
      "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
      "Setting up flac (1.3.3-2ubuntu0.2) ...\n",
      "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
      "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
      "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Setting up libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
      "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
      "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
      "Setting up antiword (0.37-16) ...\n",
      "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
      "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
      "Setting up poppler-utils (22.02.0-2ubuntu0.3) ...\n",
      "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
      "Setting up python-is-python3 (3.9.2-2) ...\n",
      "Setting up libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.5) ...\n",
      "Setting up swig (4.0.2-1ubuntu1) ...\n",
      "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.5) ...\n",
      "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.5) ...\n",
      "Setting up python-dev-is-python3 (3.9.2-2) ...\n",
      "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
      "Setting up sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Setting up pstotext (1.9-6build1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y python-dev-is-python3 libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "URlQGGwykatg",
    "outputId": "6d328cbd-973e-424b-8d43-ca1320977f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.8.3\n",
      "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.3) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.3) (1.11.4)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.3) (1.16.0)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.3) (6.4.0)\n",
      "Building wheels for collected packages: gensim\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Building wheel for gensim (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Failed building wheel for gensim\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for gensim\n",
      "Failed to build gensim\n",
      "\u001b[31mERROR: Could not build wheels for gensim, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBWTZwGfjme-",
    "outputId": "8240318c-5ce9-4643-c5a8-bc36b25871f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.8.3\n",
      "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.3) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.3) (1.11.4)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.3) (1.16.0)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.3) (6.4.0)\n",
      "Building wheels for collected packages: gensim\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Building wheel for gensim (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Failed building wheel for gensim\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for gensim\n",
      "Failed to build gensim\n",
      "\u001b[31mERROR: Could not build wheels for gensim, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "WsCTWsg-jMkZ",
    "outputId": "5a4465c9-39da-4b19-e434-2ce5a6075ada"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-3feaff075057>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbm25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim.summarization'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "from gensim.summarization import bm25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "KZGxbgdJTrDU"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTqUk4vMlROA",
    "outputId": "c43af7a0-fdb3-4504-9fb4-67373e5f186b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.23.5)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "v5WAIX5alLqx"
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "id": "-HoAEIgaJxEf"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import ndcg_score, average_precision_score\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "class InvertedIndex:\n",
    "    def __init__(self) -> None:\n",
    "        self.index = defaultdict(dict)\n",
    "        self.doc_lengths = {}\n",
    "        self.avgdl = 0\n",
    "        self.idf = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess_text(text):\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        ps = PorterStemmer()\n",
    "        text = text.lower()\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [ps.stem(token) for token in tokens if token.isalnum() and token not in stop_words]\n",
    "        return tokens\n",
    "\n",
    "    def load_file(self, file_name):\n",
    "        file_extension = file_name.split('.')[-1].lower()\n",
    "\n",
    "        if file_extension == 'csv':\n",
    "            self.docs = pd.read_csv(file_name)\n",
    "        elif file_extension == 'tsv':\n",
    "            self.docs = pd.read_csv(file_name, delimiter='\\t',header=None)\n",
    "            self.docs.columns = ['pid', 'passage']\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Supported formats: CSV (.csv) and TSV (.tsv)\")\n",
    "\n",
    "    def build_index(self, file_name: str):\n",
    "        self.load_file(file_name=file_name)\n",
    "\n",
    "        self.docs['passage'] = self.docs['passage'].apply(InvertedIndex.preprocess_text)\n",
    "\n",
    "        total_tokens = 0\n",
    "        for index, row in self.docs.iterrows():\n",
    "            doc_id, tokens = row['pid'], row['passage']\n",
    "            total_tokens += len(tokens)\n",
    "            for term in tokens:\n",
    "                self.index[term][doc_id] = self.index[term].get(doc_id, 0) + 1\n",
    "\n",
    "            self.doc_lengths[doc_id] = len(tokens)\n",
    "\n",
    "        self.avgdl = total_tokens / len(self.docs)\n",
    "        self.compute_idf()\n",
    "\n",
    "    def compute_idf(self):\n",
    "        total_docs = len(self.docs)\n",
    "        for term in self.index:\n",
    "            doc_freq = len(self.index[term])\n",
    "            self.idf[term] = math.log((total_docs - doc_freq + 0.5) / (doc_freq + 0.5) + 1.0)\n",
    "\n",
    "    def save_index(self, file_name: str):\n",
    "        with gzip.open(file_name, 'wb', compresslevel=5) as file:\n",
    "            pickle.dump({'index': self.index, 'doc_lengths': self.doc_lengths, 'avgdl': self.avgdl, 'idf': self.idf}, file)\n",
    "\n",
    "    def load_index(self, file_name: str):\n",
    "        with gzip.open(file_name, 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "            self.index = data['index']\n",
    "            self.doc_lengths = data['doc_lengths']\n",
    "            self.avgdl = data['avgdl']\n",
    "            self.idf = data['idf']\n",
    "\n",
    "\n",
    "class RetrievalModel:\n",
    "    def __init__(self, index: InvertedIndex) -> None:\n",
    "        self.index = index\n",
    "        self.len_C = len(self.index.index)\n",
    "\n",
    "    def preselect_docs(self, query, min_selected_docs=2):\n",
    "        query_terms = set(query)\n",
    "\n",
    "        relevant_docs = set()\n",
    "\n",
    "        for term in query_terms:\n",
    "            relevant_docs.update(self.index.index.get(term, {}).keys())\n",
    "\n",
    "        while len(relevant_docs) < min_selected_docs:\n",
    "            all_docs = set(self.index.doc_lengths.keys())\n",
    "            additional_doc = random.choice(list(all_docs))\n",
    "            relevant_docs.add(additional_doc)\n",
    "\n",
    "        return relevant_docs\n",
    "\n",
    "    def query_likelihood(self, query, lambd):\n",
    "        scores = {}\n",
    "\n",
    "        # for doc_id, len_doc in self.index.doc_lengths.items():\n",
    "        for doc_id in self.preselect_docs(query):\n",
    "            len_doc = self.index.doc_lengths[doc_id]\n",
    "            if len_doc == 0:\n",
    "                continue\n",
    "            p_q_Md = 0\n",
    "            for term in query:\n",
    "                df = self.index.index.get(term, {}).get(doc_id, 0)\n",
    "                cf = sum(self.index.index[term].values())\n",
    "\n",
    "                ts = (1 - lambd) * (df / len_doc) + (lambd * (cf / self.len_C))\n",
    "                if ts != 0:\n",
    "                    p_q_Md += math.log(ts)\n",
    "\n",
    "            scores[doc_id] = p_q_Md\n",
    "\n",
    "        sorted_scores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)}\n",
    "        #print(len(sorted_scores))\n",
    "        return sorted_scores\n",
    "\n",
    "    def bm25_ranking(self, query):\n",
    "        # Hyperparams to specify\n",
    "        k1 = 1.2\n",
    "        b = 0.75\n",
    "        scores = {}\n",
    "\n",
    "        # Looping through the different docs\n",
    "        # for doc_id, len_doc in self.index.doc_lengths.items():\n",
    "        #print(self.index)\n",
    "        for doc_id in self.preselect_docs(query):\n",
    "            len_doc = self.index.doc_lengths[doc_id]\n",
    "            if len_doc == 0:\n",
    "                continue\n",
    "            score = 0\n",
    "\n",
    "            # Loop for term in query in the doc\n",
    "            for term in query:\n",
    "                # Calculating/updating the score\n",
    "                tf =  self.index.index.get(term, {}).get(doc_id, 0)\n",
    "                idf_value = self.index.idf.get(term, 0)  # Use 0 as the default value if term is not in idf\n",
    "                score += idf_value * ((tf * (k1 + 1)) / (tf + k1 * (1 - b + b * len_doc / self.index.avgdl)))\n",
    "\n",
    "            scores[doc_id] = score\n",
    "\n",
    "        # sort scores / ranking\n",
    "        #print(scores)\n",
    "        sorted_scores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)}\n",
    "        #print(len(sorted_scores))\n",
    "        # print('-------------------------')\n",
    "        # print(sorted_scores)\n",
    "        # print('-----------------------')\n",
    "        # print(len(sorted_scores))\n",
    "        # print(sorted_scores)\n",
    "        return sorted_scores\n",
    "\n",
    "    def bm25_ranking_comparison(self, query):\n",
    "\n",
    "        scores = {}\n",
    "\n",
    "        corpus_df = pd.read_csv(corpus)\n",
    "\n",
    "\n",
    "\n",
    "        corpus_df = corpus_df[corpus_df['pid'].isin(list(self.preselect_docs(query)))]\n",
    "\n",
    "        #print(\"comp\", len(corpus_df))\n",
    "\n",
    "        #print(corpus_df.head(5))\n",
    "\n",
    "        # Tokenize the corpus\n",
    "        tokenized_corpus = [doc.split() for doc in corpus_df['passage']]\n",
    "\n",
    "\n",
    "\n",
    "        # Create a BM25 instance\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "        #print(bm25)\n",
    "\n",
    "\n",
    "        # Compute the BM25 scores\n",
    "        scores = bm25.get_scores(query)\n",
    "\n",
    "        scores = dict(zip(list(corpus_df['pid']), list(scores)))\n",
    "\n",
    "\n",
    "        # Sort the scores\n",
    "        sorted_scores = dict(sorted(scores.items(), key=lambda item: item[1], reverse=True))\n",
    "        # print('-------------------------')\n",
    "        # print(sorted_scores)\n",
    "        # print('-----------------------')\n",
    "\n",
    "        #print(len(sorted_scores))\n",
    "        # print(len(sorted_scores))\n",
    "        # print(sorted_scores)\n",
    "        # print(\"----------------\")\n",
    "\n",
    "        return sorted_scores\n",
    "\n",
    "    def evaluate_model(self, qrel_file, query_file, lambd=0.5, output_file='evaluation_results.csv', corpus = 'collection_small.csv'):\n",
    "        # Parse qrel file\n",
    "        qrel_data = pd.read_csv(qrel_file)\n",
    "\n",
    "        # Read query file and preprocess queries\n",
    "        query_data = pd.read_csv(query_file)\n",
    "        query_data['query'] = query_data['query'].apply(self.index.preprocess_text)\n",
    "\n",
    "        # Create a DataFrame to store results\n",
    "        results = pd.DataFrame(columns=['qid','ql_ndcg', 'bm25_ndcg', 'comp_ndcg'])\n",
    "        results['qid'] = query_data['qid']\n",
    "        results['ql_ndcg'] = None\n",
    "        results['bm25_ndcg'] = None\n",
    "        results['comp_ndcg'] = None\n",
    "\n",
    "        # Evaluate each query\n",
    "        for qid, query in zip(query_data['qid'], query_data['query']):\n",
    "            relevant_docs = qrel_data[(qrel_data['Topic'] == qid) & (qrel_data['Relevancy'] == 1)]['Document#'].tolist()\n",
    "\n",
    "            # Query Likelihood\n",
    "            ql_scores = self.query_likelihood(query, lambd)\n",
    "            ranked_docs_ql = np.array(list(ql_scores.keys()))\n",
    "            ranked_values_ql = np.array(list(ql_scores.values()))\n",
    "\n",
    "            # Create binary list for relevant and non-relevant documents\n",
    "            y_true_ql = np.isin(ranked_docs_ql, relevant_docs)\n",
    "\n",
    "            # BM25\n",
    "            bm25_scores = self.bm25_ranking(query)\n",
    "            ranked_docs_bm25 = np.array(list(bm25_scores.keys()))\n",
    "            ranked_values_bm25 = np.array(list(bm25_scores.values()))\n",
    "\n",
    "            # Create binary list for relevant and non-relevant documents\n",
    "            y_true_bm25 = np.isin(ranked_docs_bm25, relevant_docs)\n",
    "\n",
    "            # comparison\n",
    "            #print(query)\n",
    "            comp_scores = self.bm25_ranking_comparison(query, corpus)\n",
    "            ranked_docs_comp = np.array(list(comp_scores.keys()))\n",
    "            ranked_values_comp = np.array(list(comp_scores.values()))\n",
    "\n",
    "            # Create binary list for relevant and non-relevant documents\n",
    "            y_true_comp = np.isin(ranked_docs_comp, relevant_docs)\n",
    "\n",
    "            # Calculate NDCG scores\n",
    "            ndcg_ql = ndcg_score([y_true_ql], [ranked_values_ql])\n",
    "            ndcg_bm25 = ndcg_score([y_true_bm25], [ranked_values_bm25])\n",
    "            ndcg_comp = ndcg_score([y_true_comp], [ranked_values_comp])\n",
    "\n",
    "            # print(\"ql:\", ndcg_ql, \"rank\", np.where(ranked_docs_ql == relevant_docs))\n",
    "            # print(\"bm25:\", ndcg_bm25, \"rank\", np.where(ranked_docs_bm25 == relevant_docs))\n",
    "\n",
    "            # Append results to the DataFrame\n",
    "            results.loc[results['qid'] == qid] = [qid, ndcg_ql, ndcg_bm25, ndcg_comp]\n",
    "\n",
    "        # Save results to a CSV file\n",
    "        results.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "id": "e75LEQfLJxEg"
   },
   "outputs": [],
   "source": [
    "data_fine_name = \"collection_small.csv\"\n",
    "# data_fine_name = r\"data\\collection.tsv\"\n",
    "index_file_name = 'index2.json.gz'\n",
    "\n",
    "index = InvertedIndex()\n",
    "build = True\n",
    "\n",
    "if build:\n",
    "    index.build_index(data_fine_name)\n",
    "    index.save_index(index_file_name)\n",
    "else:\n",
    "    index.load_index(index_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "id": "v33HItCyUHH_"
   },
   "outputs": [],
   "source": [
    "# with open('iindex9', 'wb') as f:\n",
    "#   pickle.dump(index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "id": "4r9tTODuJxEh"
   },
   "outputs": [],
   "source": [
    "query_file = \"queries_small.csv\"\n",
    "qrel_file = \"qrel_small.csv\"\n",
    "corpus = \"collection_small.csv\"\n",
    "retrival_model = RetrievalModel(index)\n",
    "\n",
    "retrival_model.evaluate_model(qrel_file, query_file, corpus = corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "id": "o-Ldtc9MJxEh"
   },
   "outputs": [],
   "source": [
    "query_file = \"queries_small.csv\"\n",
    "qrel_file = \"qrel_small.csv\"\n",
    "retrival_model = RetrievalModel(index)\n",
    "\n",
    "retrival_model.evaluate_model(qrel_file, query_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdKmXEMpJxEh",
    "outputId": "dfb6271b-c14b-4c2b-9d23-5a36da072323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rine', 'n', 'chees']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_file = \"queries_small.csv\"\n",
    "query_data = pd.read_csv(query_file)\n",
    "query_data['query'] = query_data['query'].apply(index.preprocess_text)\n",
    "\n",
    "query = query_data['query'].iloc[1]\n",
    "\n",
    "print(query)\n",
    "\n",
    "len(retrival_model.preselect_docs(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDjbL2pHKgXE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
