{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "khje3GXF3EY5"
   },
   "outputs": [],
   "source": [
    "# Basic imports needed\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vNhZmojNCAva"
   },
   "outputs": [],
   "source": [
    "def create_index(documents):\n",
    "    \n",
    "    # Creating a dict to store the term freqs\n",
    "    index = defaultdict(dict)\n",
    "\n",
    "    # Creating a dict to store the document lengths\n",
    "    doc_len = {}\n",
    "\n",
    "    # Creating a set to store the unique terms\n",
    "    terms = set()\n",
    "\n",
    "    # Looping over the documents\n",
    "    for i, document in enumerate(documents):\n",
    "\n",
    "        # Loop over the terms in the document\n",
    "        for term in document:\n",
    "\n",
    "            # Change the term frequency\n",
    "            index[term][i] = index[term].get(i, 0) + 1\n",
    "\n",
    "            # Add the term to the set\n",
    "            terms.add(term)\n",
    "\n",
    "        # Store the length of the document\n",
    "        doc_len[i] = len(document)\n",
    "\n",
    "    # Compute the average document length\n",
    "    avgdl = sum(doc_len.values()) / len(doc_len)\n",
    "\n",
    "    # Compute the idf for each term\n",
    "    idf = {}\n",
    "\n",
    "    #print(terms)\n",
    "\n",
    "    for term in terms:\n",
    "        df = len(index[term])\n",
    "        idf[term] = math.log(len(documents)/df)\n",
    "\n",
    "\n",
    "    return index, doc_len, avgdl, idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LzK2tYavCC_e"
   },
   "outputs": [],
   "source": [
    "# documents = [\"just some text here text here here\", \"another text here\",\"just another here here \"]\n",
    "\n",
    "# Custom dataset\n",
    "\n",
    "documents2 = [\n",
    "    [\"just\", \"some\", \"text\", \"here\", \"text\", \"here\", \"here\"],\n",
    "    [\"another\", \"text\", \"here\"],\n",
    "    [\"just\", \"another\", \"here\", \"here\"]\n",
    "]\n",
    "\n",
    "tf = []\n",
    "\n",
    "for doc in documents2:\n",
    "  tf.append(dict(Counter(doc)))\n",
    "\n",
    "index, doc_len, avgdl, idf = create_index(documents2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9pk6LaYUCETa",
    "outputId": "749d786f-2e98-4045-f4fa-1b6e0ddc5020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: defaultdict(<class 'dict'>, {'just': {0: 1, 2: 1}, 'some': {0: 1}, 'text': {0: 2, 1: 1}, 'here': {0: 3, 1: 1, 2: 2}, 'another': {1: 1, 2: 1}})\n",
      "Document Lengths: {0: 7, 1: 3, 2: 4}\n",
      "Average Document Length: 4.666666666666667\n",
      "Term Frequencies per doc in order: [{'just': 1, 'some': 1, 'text': 2, 'here': 3}, {'another': 1, 'text': 1, 'here': 1}, {'just': 1, 'another': 1, 'here': 2}]\n",
      "Inverse Document Frequencies: {'text': 0.4054651081081644, 'some': 1.0986122886681098, 'another': 0.4054651081081644, 'here': 0.0, 'just': 0.4054651081081644}\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(f\"Index: {index}\")\n",
    "print(f\"Document Lengths: {doc_len}\")\n",
    "print(f\"Average Document Length: {avgdl}\")\n",
    "print(f\"Term Frequencies per doc in order: {tf}\")\n",
    "print(f\"Inverse Document Frequencies: {idf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cg6RMX71zS6D"
   },
   "source": [
    "# TF percentages rather than numbers, might be useful at some point. NOT USED NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VB7SH9BIwpX",
    "outputId": "d3814ac7-9c91-4dec-d0b7-70cd593f5060"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0: 0.5, 2: 0.5}, {0: 1.0}, {0: 0.6666666666666666, 1: 0.3333333333333333}, {0: 0.5, 1: 0.16666666666666666, 2: 0.3333333333333333}, {1: 0.5, 2: 0.5}]\n"
     ]
    }
   ],
   "source": [
    "def tf_perc(iindex):\n",
    "    tf = []\n",
    "    for doc in iindex.values():\n",
    "        term_freq = {}\n",
    "        total_words = sum(doc.values())\n",
    "        for term in doc:\n",
    "            term_freq[term] = doc[term] / total_words\n",
    "        tf.append(term_freq)\n",
    "    return tf\n",
    "\n",
    "# Example usage\n",
    "tf2 = tf_perc(index)\n",
    "print(tf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-02g2fbDG7R"
   },
   "source": [
    "Code below is inspired by: https://medium.com/@evertongomede/understanding-the-bm25-ranking-algorithm-19f6d45c6ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LZglDHf7WE_",
    "outputId": "d411d79d-3017-4b3b-8cf2-26580567c36e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 33.29319955406912, 2: 11.870680044593088, 1: 11.282051282051281}\n",
      "{0: 33.29319955406912, 2: 11.870680044593088, 1: 11.282051282051281}\n"
     ]
    }
   ],
   "source": [
    "#BM25 ranking algorithm\n",
    "\n",
    "# def bm25_ranking_index(index, query):\n",
    "#     k1 = 1.2\n",
    "#     b = 0.75\n",
    "#     scores = defaultdict(int)\n",
    "#     avgdl = sum(map(len, index.values())) / len(index)\n",
    "#     for term in query:\n",
    "#         if term in index:\n",
    "#             idf = len(index) / len(index[term])\n",
    "#             for doc_id, tf in index[term].items():\n",
    "#                 score = idf * ((tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (len(index[doc_id]) / avgdl))))\n",
    "#                 scores[doc_id] += score\n",
    "#     return dict(sorted(scores.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "def bm25_ranking(tf, idf, docs, query):\n",
    "    \n",
    "    # Hyperparams to specify\n",
    "    k1 = 1.2\n",
    "    b = 0.75\n",
    "    scores = {}\n",
    "    \n",
    "    # Looping through the different docs\n",
    "    for doc_id in range(len(docs)):\n",
    "        score = 0\n",
    "        doc = docs[doc_id]\n",
    "        \n",
    "        # Loop for term in query in the doc\n",
    "        for term in query:\n",
    "            if str(term) in list(tf[doc_id].keys()):\n",
    "                \n",
    "                # Calculating/updating the score\n",
    "                score += idf[term] * ((tf[doc_id][term] * (k1 + 1)) / (tf[doc_id][term] + k1 * (1 - b + b * (len(doc) / avgdl))))\n",
    "\n",
    "        scores[doc_id] = score\n",
    "    # sort scores / ranking\n",
    "    sorted_scores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return sorted_scores\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Example usage\n",
    "query = [\"just\", \"some\", \"text\", \"here\"]\n",
    "scores = bm25_ranking(tf, idf, documents2, query)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUGEZz9tnRUN"
   },
   "outputs": [],
   "source": [
    "# from relevancy import relevancy_lookup\n",
    "# import csv\n",
    "\n",
    "# def process_qrel_file(qrel_path):\n",
    "#     relevancies = relevancy_lookup()\n",
    "\n",
    "#     with open(qrel_path) as file:\n",
    "#         qrel_file = csv.reader(file, delimiter=\"\\t\")\n",
    "#         for line in qrel_file:\n",
    "#             query, document, relevancy = parse_qrel_line(line)\n",
    "#             relevancies.add(query, document, relevancy)\n",
    "#     return relevancies\n",
    "\n",
    "# def parse_qrel_line(line):\n",
    "#     #query_id, _, document_id, relevance\n",
    "#     line = line[0].split()\n",
    "#     return int(line[0]), line[2], int(line[3])\n",
    "\n",
    "# qrel_path = \"msmarco-docdev-qrels.tsv\"\n",
    "# relevancies = process_qrel_file(qrel_path)\n",
    "# print(relevancies.relevancies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QaUzfAA-ReXF",
    "outputId": "fae79330-8822-4909-a4ff-4e0e07154727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         108G   27G   81G  26% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "shm             5.8G     0  5.8G   0% /dev/shm\n",
      "/dev/root       2.0G  1.1G  885M  55% /usr/sbin/docker-init\n",
      "tmpfs           6.4G  208K  6.4G   1% /var/colab\n",
      "/dev/sda1        44G   28G   16G  65% /etc/hosts\n",
      "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
      "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
      "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pzbu_RpRe2P",
    "outputId": "0d9a642b-e10c-4132-8010-e12af2f46209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor\t: 0\n",
      "vendor_id\t: AuthenticAMD\n",
      "cpu family\t: 23\n",
      "model\t\t: 49\n",
      "model name\t: AMD EPYC 7B12\n",
      "stepping\t: 0\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 2249.998\n",
      "cache size\t: 512 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 0\n",
      "initial apicid\t: 0\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ssbd ibrs ibpb stibp vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 clzero xsaveerptr arat npt nrip_save umip rdpid\n",
      "bugs\t\t: sysret_ss_attrs null_seg spectre_v1 spectre_v2 spec_store_bypass retbleed smt_rsb\n",
      "bogomips\t: 4499.99\n",
      "TLB size\t: 3072 4K pages\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 48 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n",
      "processor\t: 1\n",
      "vendor_id\t: AuthenticAMD\n",
      "cpu family\t: 23\n",
      "model\t\t: 49\n",
      "model name\t: AMD EPYC 7B12\n",
      "stepping\t: 0\n",
      "microcode\t: 0xffffffff\n",
      "cpu MHz\t\t: 2249.998\n",
      "cache size\t: 512 KB\n",
      "physical id\t: 0\n",
      "siblings\t: 2\n",
      "core id\t\t: 0\n",
      "cpu cores\t: 1\n",
      "apicid\t\t: 1\n",
      "initial apicid\t: 1\n",
      "fpu\t\t: yes\n",
      "fpu_exception\t: yes\n",
      "cpuid level\t: 13\n",
      "wp\t\t: yes\n",
      "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid tsc_known_freq pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm cmp_legacy cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw topoext ssbd ibrs ibpb stibp vmmcall fsgsbase tsc_adjust bmi1 avx2 smep bmi2 rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 clzero xsaveerptr arat npt nrip_save umip rdpid\n",
      "bugs\t\t: sysret_ss_attrs null_seg spectre_v1 spectre_v2 spec_store_bypass retbleed smt_rsb\n",
      "bogomips\t: 4499.99\n",
      "TLB size\t: 3072 4K pages\n",
      "clflush size\t: 64\n",
      "cache_alignment\t: 64\n",
      "address sizes\t: 48 bits physical, 48 bits virtual\n",
      "power management:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xzEDL_nRkVR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
